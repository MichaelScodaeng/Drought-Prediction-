{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ed47ad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added project root to sys.path: c:\\Users\\peera\\Desktop\\DroughtLSTM_oneday\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\peera\\.conda\\envs\\drought_lstm_base\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch, PyTorch Lightning, and Optuna successfully imported.\n",
      "ConvLSTM Pipeline: Successfully imported utility functions.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\peera\\.conda\\envs\\drought_lstm_base\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.1 is exactly one major version older than the runtime version 6.31.1 at api.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Add project root to Python path to find the 'src' directory\n",
    "notebook_dir = os.getcwd()\n",
    "project_root = os.path.abspath(os.path.join(notebook_dir, '..'))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "    print(f\"Added project root to sys.path: {project_root}\")\n",
    "\n",
    "# Import your new ConvLSTM pipeline class\n",
    "from src.improved_convlstm_multitask_pipeline import MultitaskConvLSTMPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1dcc7c64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Could not import from data_utils_v1 for __main__ block. Ensure it's accessible.\n",
      "Configuration loaded from ../config/cnn2dlstm/config_cnn2dlstm_TEST.yaml\n",
      "Successfully loaded data from c:\\Users\\peera\\Desktop\\DroughtLSTM_oneday\\data\\full.csv. Shape: (264204, 19)\n",
      "Converted column 'time' to datetime.\n",
      "Data sorted by ['time', 'lat', 'lon'].\n",
      "Splitting data: Train ends 2017-12-31 00:00:00, Validation ends 2020-12-31 00:00:00\n",
      "Train set shape: (251316, 19), Time range: 1901-01-16 00:00:00 to 2017-12-16 00:00:00\n",
      "Validation set shape: (6444, 19), Time range: 2018-01-16 00:00:00 to 2020-12-16 00:00:00\n",
      "Test set shape: (6444, 19), Time range: 2021-01-16 00:00:00 to 2023-12-16 00:00:00\n",
      "Columns to be scaled using robust scaler: ['pre', 'tmp', 'dtr', 'cld', 'tmx', 'tmn', 'wet', 'vap', 'soi', 'dmi', 'pdo', 'nino4', 'nino34', 'nino3', 'pet', 'pre']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\peera\\Desktop\\DroughtLSTM_oneday\\src\\data_utils.py:59: UserWarning: Parsing dates in %d/%m/%Y format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  df[time_col] = pd.to_datetime(df[time_col])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data scaling complete.\n",
      "--- Starting Data Gridding Process (Fixed Step Method) ---\n",
      "Using fixed grid step of: 0.5 degrees\n",
      "Grid boundaries: LAT (6.25, 20.25), LON (97.75, 105.25)\n",
      "Calculated grid dimensions: Height=29, Width=16\n",
      "Created 2D validity mask (29x16) with 179 valid data pixels.\n",
      "Pivoting data into a 4D tensor of shape (1404, 29, 16, 15)...\n",
      "--- Data Gridding Process Finished ---\n",
      "--- Starting Data Gridding Process (Fixed Step Method) ---\n",
      "Using fixed grid step of: 0.5 degrees\n",
      "Grid boundaries: LAT (6.25, 20.25), LON (97.75, 105.25)\n",
      "Calculated grid dimensions: Height=29, Width=16\n",
      "Created 2D validity mask (29x16) with 179 valid data pixels.\n",
      "Pivoting data into a 4D tensor of shape (36, 29, 16, 15)...\n",
      "--- Data Gridding Process Finished ---\n",
      "--- Starting Data Gridding Process (Fixed Step Method) ---\n",
      "Using fixed grid step of: 0.5 degrees\n",
      "Grid boundaries: LAT (6.25, 20.25), LON (97.75, 105.25)\n",
      "Calculated grid dimensions: Height=29, Width=16\n",
      "Created 2D validity mask (29x16) with 179 valid data pixels.\n",
      "Pivoting data into a 4D tensor of shape (36, 29, 16, 15)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-14 03:20:37,653] A new study created in memory with name: no-name-b0888adc-061d-4939-a7a9-1bbc3068d43a\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Data Gridding Process Finished ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\peera\\Desktop\\DroughtLSTM_oneday\\src\\cnn2dlstmpipeline.py:361: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "[I 2025-06-14 03:20:41,488] Trial 0 finished with value: 0.04434926621615887 and parameters: {'batch_size': 16, 'hidden_cnn': 32, 'kernel_size': 3, 'lstm_hidden_size': 128, 'lstm_layers': 2, 'dropout': 0.1943396273978294, 'learning_rate': 0.00034096871037072094}. Best is trial 0 with value: 0.04434926621615887.\n",
      "[I 2025-06-14 03:20:44,292] Trial 1 finished with value: 0.03584557771682739 and parameters: {'batch_size': 16, 'hidden_cnn': 16, 'kernel_size': 3, 'lstm_hidden_size': 128, 'lstm_layers': 2, 'dropout': 0.42114892686425087, 'learning_rate': 0.0016949784448918733}. Best is trial 1 with value: 0.03584557771682739.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial: {'batch_size': 16, 'hidden_cnn': 16, 'kernel_size': 3, 'lstm_hidden_size': 128, 'lstm_layers': 2, 'dropout': 0.42114892686425087, 'learning_rate': 0.0016949784448918733}\n",
      "Retraining final model with best params...\n",
      "Epoch 1/2 - Val Loss: 0.0474\n",
      "✅ New best model saved to c:\\Users\\peera\\Desktop\\DroughtLSTM_oneday\\config\\cnn2dlstm\\..\\..\\models_saved\\cnn2dlstm_test\\cnnlstm_best_model.pt\n",
      "Epoch 2/2 - Val Loss: 0.0402\n",
      "✅ New best model saved to c:\\Users\\peera\\Desktop\\DroughtLSTM_oneday\\config\\cnn2dlstm\\..\\..\\models_saved\\cnn2dlstm_test\\cnnlstm_best_model.pt\n",
      "Final model saved to c:\\Users\\peera\\Desktop\\DroughtLSTM_oneday\\config\\cnn2dlstm\\..\\..\\models_saved\\cnn2dlstm_test\\cnnlstm_final_model.pt\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "boolean index did not match indexed array along axis 0; size of axis is 645888 but size of corresponding boolean axis is 80736",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 15\u001b[0m\n\u001b[0;32m     12\u001b[0m pipeline\u001b[38;5;241m.\u001b[39mtune_and_train(n_trials\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# --- 4. Evaluate Performance ---\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m metrics \u001b[38;5;241m=\u001b[39m \u001b[43mpipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# --- 5. Save Full Data Predictions ---\u001b[39;00m\n\u001b[0;32m     18\u001b[0m pred_df \u001b[38;5;241m=\u001b[39m pipeline\u001b[38;5;241m.\u001b[39mpredict_on_full_data()\n",
      "File \u001b[1;32mc:\\Users\\peera\\Desktop\\DroughtLSTM_oneday\\src\\cnn2dlstmpipeline.py:251\u001b[0m, in \u001b[0;36mCNNLSTMPipeline.evaluate\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    248\u001b[0m preds_flat \u001b[38;5;241m=\u001b[39m preds\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    249\u001b[0m actuals_flat \u001b[38;5;241m=\u001b[39m actuals\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m--> 251\u001b[0m preds_valid \u001b[38;5;241m=\u001b[39m \u001b[43mpreds_flat\u001b[49m\u001b[43m[\u001b[49m\u001b[43mvalid_mask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrepeat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m    252\u001b[0m actuals_valid \u001b[38;5;241m=\u001b[39m actuals_flat[valid_mask\u001b[38;5;241m.\u001b[39mrepeat(actuals\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)]\n\u001b[0;32m    254\u001b[0m preds_inv \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_scaler\u001b[38;5;241m.\u001b[39minverse_transform(preds_valid\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n",
      "\u001b[1;31mIndexError\u001b[0m: boolean index did not match indexed array along axis 0; size of axis is 645888 but size of corresponding boolean axis is 80736"
     ]
    }
   ],
   "source": [
    "# --- 1. Setup ---\n",
    "import os\n",
    "from src.cnn2dlstmpipeline import CNNLSTMPipeline  # adapt this import if you rename or move your pipeline script\n",
    "\n",
    "# Set config path\n",
    "config_path = \"../config/cnn2dlstm/config_cnn2dlstm_TEST.yaml\"\n",
    "\n",
    "# --- 2. Initialize pipeline ---\n",
    "pipeline = CNNLSTMPipeline(config_path)\n",
    "\n",
    "# --- 3. Run Optuna Tuning + Training ---\n",
    "pipeline.tune_and_train(n_trials=20)\n",
    "\n",
    "# --- 4. Evaluate Performance ---\n",
    "metrics = pipeline.evaluate()\n",
    "\n",
    "# --- 5. Save Full Data Predictions ---\n",
    "pred_df = pipeline.predict_on_full_data()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drought_lstm_base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
